---
title: "5320project"
author: "Daniel Silva"
date: "5/11/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
library(coda)
library(extraDistr)
```



```{r}
set.seed(53202022)
data <- read.csv("voter_roll.csv") 
called <- data[(data$answer_phone>0),]
summary(data)
```



```{r}
draw_beta <- function(alpha,beta,clr="black",new_plot=TRUE) {
	xs <- seq(0,1,.0001)
	ys <- dbeta(xs,alpha,beta)
	if (new_plot) plot(xs,ys,type="l",xlim=c(0,1),ylim=c(0,10),col=clr)
	else lines(xs,ys,col=clr)
	abline(h=0,v=c(0,1),col="gray")
}
draw_beta(12,8)

# Prior density parameters guess
alpha = 12
beta = 8

# plot the prior density):
xs <- seq(0,1,.001)
ys <- dbeta(xs,alpha,beta)
plot(NA,NA,xlim=c(0,1),ylim=c(0,5))
abline(h=0,v=c(0,1))
lines(xs,ys)
```

## Problem 1 a)


```{r}
A <- seq(1,100,.1)
B <- seq(1,100,.1)
min <- 0.1

for (a in A){
  for (b in B){
    prob <- (pbeta(.6,a,b,lower.tail = FALSE))+(pbeta(.4,a,b)) # P(.4>pi)+P(pi<.6)
    temp <- abs(.05-prob)
    #aindex <- append(a,aindex)
    #bindex <- append(b,bindex)
    #prob_temp <- append(prob,prob_temp)
    
    if(temp < min){
      min <- temp
      besta <- a
      bestb <- b
      bestprob <- prob
    }
  }
}
```

```{r}
A <- seq(0,20,.1)
B <- seq(0,20,.1)
aindex = 0
bindex = 0
min <- 0.1
bestprob = 1
prob_temp = 1
atemp = 0
btemp = 0
for (a in A){
  for (b in B){
    prob <- (pbeta(.6,a,b,lower.tail = FALSE))+(pbeta(.4,a,b)) # P(.4>pi)+P(pi<.6)
    err <- abs(.05-prob)
    #aindex <- append(a,aindex)
    #bindex <- append(b,bindex)
    prob_temp <- append(prob,prob_temp)
    atemp <- append(a,atemp)
    btemp <- append(b,btemp)
    if(err < min){
      #min <- err
      #aindex <- append(a,aindex)
      #bestb <- append(b,bindex)
      #bestprob <- append(prob,bestprob)
    }
  }
}
```



```{r}
besta = 49.5
bestb = 49.5
#draw_beta(besta,bestb)
print(pbeta(.6,besta,bestb,lower.tail = FALSE))
print(pbeta(.4,besta,bestb))
print(pbeta(.6,besta,bestb,lower.tail = FALSE)+pbeta(.4,besta,bestb))
besta
```

```{r}
plot_ly(x = atemp,y = btemp,z = prob_temp,type = "contour")
```

# Plotting the beta prior and beta post

```{r}
alpha <- 47.3
beta <- 47.3

y <- (called$vote)[1:95]
ysum <- sum(y)
ymean <- mean(y)
n <- 95

alpha_post <- alpha + ysum 
beta_post <- beta + n - ysum
xs = seq(0,1,0.001)

prior_dist = dbeta(xs,alpha,beta)
post_dist= dbeta(xs,alpha_post,beta_post)

draw_beta(alpha,beta)
draw_beta(alpha_post,beta_post,clr = "red",new_plot = FALSE)

mean_post <- alpha_post/(alpha_post+beta_post)
var_post <- (alpha_post*beta_post)/((alpha_post+beta_post)*(alpha_post+beta_post)*(alpha_post+beta_post+1))

pi_s <- pbeta(.5,alpha_post,beta_post,lower.tail = FALSE)

# Variance of the posterior
print(var_post)
# Mean of the posterior 
print(mean_post)
# Probability of Gray Winning
print(pi_s)
```

## Problem 1 b)


```{r}
etaTransform <- function(eta){
  exp(eta)/(1+exp(eta))
}

mu_prior = 0.5
var_prior = 0.0025
eta_prior = dnorm(xs,mu_prior,var_prior)

var_true = var(y)



mu = ymean


# Plot the prior and posterior densities:
plot(NA,NA,type="n",xlim=c(0,1),ylim=c(0,10),xlab="y",ylab="Density")
abline(h=0)
# plot the prior density in red: 
lines(xs,dnorm(xs,mu_prior,sqrt(var_prior)),col="red")
#### plot the data density( the posterior density we would get
#### with a completely flat prior):
####lines(xs,dnorm(xs,mean(y),sqrt(var_true/n)),col ="blue")

# calculate the parameters of the posterior:
mu_n = (ymean*n/var_true + mu_prior/var_prior)/(n/var_true + 1/var_prior)
var_n = 1/(n/var_true + 1/var_prior)
#add the posterior curve to the plot:
lines(xs,dnorm(xs,mu_n,sqrt(var_n)),col="purple")


```

# Metropolis Algorithm on normal distribution


```{r}
# Metropolis Algorithm

# My prior distribution for eta ~N(0.5,0.0025)
mu_prior = 0.5
var_prior = 0.05

# Prior Distribution 
eta_prior = dnorm(xs,mu_prior,var_prior)

# True/Exact population variance:
var_true = var(y)

# current value of mu (initialized to sample mean of y)
mu = ymean

# Counts
a = 0

# Number of chains iterations
S <- 10000

# mu values for all S elements in the chain
mu_s = numeric(S)

for (s in 1:S){
  # propose a new value for the chain
  mu_star = mu + rnorm(1,0,sqrt(var_prior))
  #mu_star = mu + rnorm(1,mu_prior,sqrt(var_prior))
  
  prior_density_ratio = dnorm(mu_star,mu_prior,sqrt(var_prior)) / dnorm(mu,mu_prior,sqrt(var_prior))
  
  liklihood_ratio = prod(dnorm(y,mu_star,sqrt(var_true))) / prod(dnorm(y,mu,sqrt(var_true)))
  log_target_ratio = dnorm(mu_star,ymean,sqrt(.005),log=TRUE) - dnorm(mu,ymean,sqrt(.005),log=TRUE)
  
  # accept with the appropriate probability:
  #if(runif(1) < prior_density_ratio*liklihood_ratio) {
  if(log(runif(1)) < log_target_ratio) {
    mu = mu_star
    a = a+1
  }
  # Save the next value in the chain
  mu_s[s] = mu #etaTransform(mu)
}

# histograms of posterior samples:
hist(mu_s,prob=TRUE)
# add the posterior curve to the plot:
lines(xs,dnorm(xs,mu_n,sqrt(.005)),col="purple")

# Acceptance Rate
acceptanceRate = a/S
cat("acceptace rate: ",acceptaceRate,"\n")

# Trace Plot 
plot(1:5000,mu_s[1:5000],type="l")

# effective sample size 
effectSamSize = effectiveSize(mu_s)
effectSamSize

# MCMC efficiency 
mcmcEff = effectiveSize(mu_s)/S
cat("MCMC eff: ",mcmcEff,"\n")

# Metropolis Mean 
metroMean = mean(mu_s)
cat("Metro Mean: ",metroMean,"\n")

# Metropolis Var 
metroVar = var(mu_s)
cat("Metro Var: ",metroVar,"\n")
```

# Analysing Burn and Computing the probability of winning

```{r}
# Analyzing Post Burn in
# look a the trace, zoomed in to the first 1000 iterations:
ss = 1:1000
plot(ss,mu_s[ss],type="l")

my_acf <- function(x,k) {
  cor(x[-(1:k)],x[-((length(x)-k+1):length(x))])
}

xs <- seq(0,1,.001)

# we only want to pay us the values past 500
ss <- 501:S

# calculate lag-20 autocorrelation 
my_acf(mu_s[ss],20)

# calc autocorr out to lag 100:
acs <- numeric(100)
for (i in 1:100) acs[i] <- my_acf(mu_s[ss],i)
plot(1:100,acs,type="l")
abline(h=0)

betterEF <- effectiveSize(mu_s[ss])/length(ss)



# Plot the prior and posterior densities:
plot(NA,NA,type="n",xlim=c(0,1),ylim=c(0,10),xlab="y",ylab="Density")
abline(h=0)
# plot the prior density in red: 
lines(xs,dnorm(xs,mu_prior,var_prior),col="red")
lines(xs,dnorm(xs,metroMean,sqrt(metroVar)),col="blue")

probWinMetro = pnorm(.5,metroMean,sqrt(metroVar),lower.tail = FALSE)


cat("Post Mean : ",metroMean,"\n")
cat("Post Var: ",(metroVar),"\n")
cat("Metro Prob: ",probWinMetro,"\n")
```
# Problem 3


```{r}
xn = seq(1,800)
xsn = seq(0,1,length.out = 800)

# Proportion of the theoretical population of all voters
pi_dist_prior = dbeta(xs,alpha,beta)

# number of voters from the sample voting for Gary
y0 = ysum

# Total number of actual voters
N = 800

# Y bin(N-n,pi)
#y_dist_prior = rbinom(10000,N-n,pi_dist_prior) 
y_dist_prior = dbbinom(xn,N-n,alpha,beta)
y_dist_post = dbbinom(xn,N-n,alpha_post,beta_post)

#plot(y_dist_prior)

# Prior Density for pi hat
#pi_n = (y0-y_dist_prior)/N
plot(NA,NA,xlim=c(1,800),ylim =c(0,.02))
abline(h=0,v=c(0,1))
lines(xn,y_dist_prior,col = "red")
lines(xn,y_dist_post,col = "blue")

betaBinMean = alpha_post/(alpha+beta+n)
betaBinVar = (alpha_post*beta_post)/(((alpha+beta+n)^2)*(alpha+beta+n+1))

probBetaBin = pbbinom(400,N-n,alpha_post,beta_post)

cat("Beta-Bin Mean: ",betaBinMean,"\n")
cat("Beta-Bin Var: ",betaBinVar,"\n")
cat("Prob Win Beta-Bin: ",probBetaBin,"\n")

```

## Problem 3 








